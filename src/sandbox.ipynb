{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Any, Union, Callable\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from configobj import ConfigObj, Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "WDIR = Path().cwd().parent\n",
    "\n",
    "PLANET_DB_PATH = str(WDIR / \"data/planet_database_composite.csv\")\n",
    "OPACITY_PATH = str(WDIR / \"data/Input/xsec/xsec_sampled_R15000_0.3-15\")\n",
    "CIA_PATH = str(WDIR / \"data/Input/cia/hitran\")\n",
    "KTABLE_PATH = str(WDIR / \"data/Input/ktables/R100\")\n",
    "MOLECULE_PATH = str(WDIR / \"data/molecule_db.json\")\n",
    "\n",
    "SPECTRA_BE_PATH = str(WDIR / \"data/SpectraBE\")\n",
    "SPECTRA_LW_PATH = str(WDIR / \"data/taurex_lightcurves_LW\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'molecule': 'H2O', 'abundance': -3, 'type': 'ConstantGas'}, {'molecule': 'CH4', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'NH3', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'CO', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'CO2', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'HCN', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'Na', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'K', 'abundance': -7, 'type': 'ConstantGas'}, {'molecule': 'TiO', 'abundance': -15, 'type': 'ConstantGas'}, {'molecule': 'VO', 'abundance': -15, 'type': 'ConstantGas'}, {'molecule': 'FeH', 'abundance': -15, 'type': 'ConstantGas'}, {'molecule': 'e-', 'abundance': -15, 'type': 'ConstantGas'}]\n"
     ]
    }
   ],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "print(read_json_file(MOLECULE_PATH))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# config = ConfigObj(str(WDIR / \"data/default.par\"))\n",
    "#\n",
    "# config\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_csv_comments(filename: str) -> list:\n",
    "    lines = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            if len(row) > 0 and row[0].startswith(\"# COLUMN\"):\n",
    "                lines.append(row[0])\n",
    "    return lines\n",
    "\n",
    "def process_lines(file_path) -> Dict:\n",
    "\n",
    "    lines = read_csv_comments(file_path)\n",
    "\n",
    "    result = {}\n",
    "    for line in lines:\n",
    "        key, value = line.replace(\"# COLUMN\", \"\").split(\":\", 1)\n",
    "        result[key.strip()] = value.strip()\n",
    "    return result\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AliasedDict(dict):\n",
    "    aliases: dict\n",
    "\n",
    "    def __init__(self, data: dict, aliases: dict):\n",
    "        super().__init__(data)\n",
    "        self.aliases = aliases\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.aliases:\n",
    "            key = self.aliases[key]\n",
    "        return super().__getitem__(key)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self.aliases:\n",
    "            key = self.aliases[key]\n",
    "        return super().__setitem__(key, value)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        if key in self.aliases:\n",
    "            key = self.aliases[key]\n",
    "        return super().__delitem__(key)\n",
    "\n",
    "    def add_alias(self, key, alias):\n",
    "        self.aliases[alias] = key\n",
    "\n",
    "\n",
    "class TaurexConfigObj(ConfigObj):\n",
    "    def _write_line(self, indent_string, entry, this_entry, comment):\n",
    "\n",
    "        try:\n",
    "            if re.search(\":fit\", entry):\n",
    "                indent_string = os.linesep + indent_string\n",
    "        except TypeError:\n",
    "            print(entry)\n",
    "        finally:\n",
    "            return super()._write_line(indent_string, entry, this_entry, comment)\n",
    "\n",
    "\n",
    "    def _write_marker(self, indent_string, depth, entry, comment):\n",
    "        \"\"\"Write a section marker line\"\"\"\n",
    "        entry_str = self._decode_element(entry)\n",
    "        title = self._quote(entry_str, multiline=False)\n",
    "        if entry_str and title[0] in '\\'\"' and title[1:-1] == entry_str:\n",
    "            # titles are in '[]' already, so quoting for contained quotes is not necessary (#74)\n",
    "            title = entry_str\n",
    "        return '%s%s%s%s%s' % (os.linesep + indent_string,\n",
    "                               '[' * depth,\n",
    "                               title,\n",
    "                               ']' * depth,\n",
    "                               self._decode_element(comment))\n",
    "\n",
    "def get_target_data(planet_name):\n",
    "    exoplanet_database = pd.read_csv(PLANET_DB_PATH, comment=\"#\", index_col=0)\n",
    "\n",
    "    target_data = exoplanet_database.loc[exoplanet_database[\"pl_name\"] == planet_name].to_dict(orient=\"records\")[0]\n",
    "\n",
    "    col_names = process_lines(PLANET_DB_PATH)\n",
    "    col_names = {v: k for k, v in col_names.items()}\n",
    "\n",
    "    target = AliasedDict(target_data, aliases=col_names)\n",
    "\n",
    "    return target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def write_global(config, settings=None):\n",
    "    config['Global']['xsec_path'] = str(OPACITY_PATH)\n",
    "    config['Global']['cia_path'] = str(CIA_PATH)\n",
    "    config['Global']['ktable_path'] = str(KTABLE_PATH)\n",
    "    config['Global']['opacity_method'] = \"xsec\"\n",
    "\n",
    "def write_chemistry(config, settings=None):\n",
    "    config['Chemistry']['chemistry_type'] = 'taurex'\n",
    "    config['Chemistry']['fill_gases'] = ['H2', 'He']\n",
    "    config['Chemistry']['ratio'] = 0.17\n",
    "\n",
    "def _write_abstract(config, settings, level=0):\n",
    "    for k, v in settings.items():\n",
    "        config[k] = {}\n",
    "        try:\n",
    "            assert isinstance(v, dict)\n",
    "            _write_abstract(config=config[k], settings=v, level=level+1)\n",
    "        except AssertionError:\n",
    "            config[k] = v\n",
    "            return\n",
    "\n",
    "\n",
    "def make_Global_dict(settings=None, **kwargs):\n",
    "\n",
    "    global_dict = {\n",
    "        'xsec_path': str(OPACITY_PATH),\n",
    "        \"cia_path\": str(CIA_PATH),\n",
    "        \"ktable_path\": str(KTABLE_PATH),\n",
    "        \"opacity_method\": \"xsec\",\n",
    "    }\n",
    "\n",
    "    return {\"Global\": global_dict}\n",
    "\n",
    "def make_Obs_ObsFit_dict(path_list=None, fit_list=None, fitting_bounds=None, fitting_mode=\"linear\", **kwargs):\n",
    "\n",
    "    if path_list is None:\n",
    "        raise ValueError\n",
    "\n",
    "    observation_dict = {\n",
    "        'observation': 'spectra_w_offsets',\n",
    "        'path_spectra': [str(p) for p in path_list],\n",
    "        'offsets': [\"0.0\"] * len(path_list),\n",
    "        'slopes': [\"0.0\"] * len(path_list),\n",
    "    }\n",
    "\n",
    "    if fitting_bounds is None:\n",
    "        fitting_bounds = ['-1e-15', '1e-15']\n",
    "\n",
    "    if fit_list is None:\n",
    "        fit_list = list(np.full_like(path_list, fill_value=True, dtype=bool))\n",
    "        fit_list[0] = False\n",
    "\n",
    "    if isinstance(fitting_bounds[0], (str, float)) and isinstance(fitting_mode, str):\n",
    "        fitting_dict = {}\n",
    "        for i, (__, fit) in enumerate(zip(path_list, fit_list)):\n",
    "\n",
    "            obs_fit_dict = {\n",
    "                f'Offset_{i+1}:fit': fit,\n",
    "                f'Offset_{i+1}:prior': f\"Uniform(bounds=({fitting_bounds[0]}, {fitting_bounds[1]}))\",\n",
    "                f'Slope_{i+1}:fit': fit,\n",
    "                f'Slope_{i+1}:prior': f\"Uniform(bounds=({fitting_bounds[0]}, {fitting_bounds[1]}))\",\n",
    "            }\n",
    "\n",
    "            fitting_dict = {**fitting_dict, **obs_fit_dict}\n",
    "    elif fitting_mode != \"linear\":\n",
    "        raise NotImplementedError(f\"Only linear fitting is implemented. Requested: {fitting_mode}\")\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only same options for each observation fit is supported.\")\n",
    "\n",
    "    out_dict = {\n",
    "        'Observation': observation_dict,\n",
    "        'Fitting': fitting_dict,\n",
    "    }\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "def make_Chem_dict(molecule_dp_path=MOLECULE_PATH, which_molecules=None,\n",
    "                   fit_list=None, fit_bounds=None, fit_modes=None,\n",
    "                   settings=None, **kwargs):\n",
    "    # TODO: use types as type hinting?\n",
    "    types = {\n",
    "        'ConstantGas': \"constant\",\n",
    "        \"TwoPointGas\": \"twopoint\",\n",
    "        'TwoLayerGas': \"twolayer\",\n",
    "        'HydrogenIon': None,\n",
    "    }\n",
    "\n",
    "    # TODO: unpack, into which gasses, k, v\n",
    "    gas_para_db = read_json_file(MOLECULE_PATH)\n",
    "    gas_para_db_dict = {gas[\"molecule\"]: gas for gas in gas_para_db}\n",
    "\n",
    "    gases_dict = {}\n",
    "    fitting_dict = {}\n",
    "\n",
    "    if which_molecules is None:\n",
    "        which_molecules = gas_para_db_dict.keys()\n",
    "\n",
    "    if fit_bounds is None:\n",
    "        fit_bounds = [[1e-16, 1e-1] for __ in which_molecules]\n",
    "\n",
    "    if fit_modes is None:\n",
    "        fit_modes = [\"LogUniform(lin_bounds=({}, {}))\"] * len(which_molecules)\n",
    "\n",
    "    if fit_list is None:\n",
    "        fit_list = list(np.full(len(which_molecules),\n",
    "                                fill_value=True,\n",
    "                                dtype=bool))\n",
    "\n",
    "    assert len(np.unique([len(l) for l in [which_molecules, fit_list, fit_bounds, fit_modes]])) == 1\n",
    "\n",
    "    # TODO: add gas_type as attr to json separate from type? for .par files\n",
    "    for i, (gas, fit_, fit_bounds, fit_mode) in enumerate(zip(which_molecules, fit_list, fit_bounds, fit_modes)):\n",
    "        try:\n",
    "            _gas = gas_para_db_dict[gas]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Gas {gas} was not found in gas DB. Possible keys: {gas_para_db.keys()}\")\n",
    "        if types[_gas[\"type\"]] == \"constant\":\n",
    "            gas_dict ={_gas[\"molecule\"]:\n",
    "                {\n",
    "                    \"gas_type\": types[_gas[\"type\"]],\n",
    "                    \"mix_ratio\": 10 ** _gas[\"abundance\"],\n",
    "                }\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            raise KeyError(f\"Gas type {types[_gas['type']]} not implemented. Gas {_gas['molecule']} requested {types[_gas['type']]}\")\n",
    "\n",
    "        # check for violated bounds\n",
    "        if 10 ** _gas[\"abundance\"] < fit_bounds[0]:\n",
    "            fit_bounds[0] = 0.1 * 10 ** _gas[\"abundance\"]\n",
    "        if 10 ** _gas[\"abundance\"] > fit_bounds[1]:\n",
    "            fit_bounds[1] = np.minimum(2. * 10 ** _gas[\"abundance\"], 0.9)\n",
    "\n",
    "        fit_dict = {\n",
    "                f'{_gas[\"molecule\"]}:fit': fit_,\n",
    "                f'{_gas[\"molecule\"]}:prior': fit_mode.format(fit_bounds[0], fit_bounds[1]),\n",
    "            }\n",
    "\n",
    "        gases_dict = {**gases_dict, **gas_dict}\n",
    "        fitting_dict = {**fitting_dict, **fit_dict}\n",
    "\n",
    "    chemistry_dict = {\n",
    "        \"chemistry_type\": \"free\",  # note: free is the same as taurex?\n",
    "        \"fill_gasses\": [\"H2\", \"He\"],\n",
    "        \"ratio\": 0.17,\n",
    "        **gases_dict,\n",
    "    }\n",
    "\n",
    "    return {\"Chemistry\": chemistry_dict, \"Fitting\": fitting_dict}\n",
    "\n",
    "\n",
    "def make_Temp_dict(target=None, settings=None, which=None, **kwargs):\n",
    "\n",
    "    if target is None:\n",
    "        raise ValueError\n",
    "\n",
    "    if settings is None:\n",
    "        settings = {}\n",
    "\n",
    "    # TODO: default is isothermal. Check re npoint or Guillot2016/2018?\n",
    "    default_iso_dict = {\n",
    "        \"profile_type\": \"isothermal\",\n",
    "        \"T\": target[\"Equilibrium Temperature [K]\"],\n",
    "    }\n",
    "\n",
    "    default_guillot_dict = {\n",
    "        \"profile_type\": \"guillot\",\n",
    "        \"T_irr\": target[\"Equilibrium Temperature [K]\"],\n",
    "        # rest is defaults for now\n",
    "    }\n",
    "    if which is None:\n",
    "        default_dict = default_guillot_dict\n",
    "    elif which == \"isothermal\":\n",
    "        default_dict = default_iso_dict\n",
    "    elif which == \"guillot\":\n",
    "        default_dict = default_guillot_dict\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # TODO: issues because errors are thrown if unexpected keys in Temperature config\n",
    "    # overwrite partial if type key is same, overwrite fully if mismatch\n",
    "    return {\"Temperature\": {**default_dict, **settings}}\n",
    "\n",
    "\n",
    "def make_Press_dict(settings=None, **kwargs):\n",
    "    if settings is None:\n",
    "        settings = {}\n",
    "\n",
    "    return {\"Pressure\": settings}\n",
    "\n",
    "\n",
    "def make_Planet_dict(target=None, settings=None, **kwargs):\n",
    "    if target is None:\n",
    "        raise ValueError\n",
    "    if settings is None:\n",
    "        settings = {}\n",
    "\n",
    "    keys_header =[\n",
    "        \"planet_mass\",\n",
    "        \"planet_radius\",\n",
    "        \"planet_distance\",\n",
    "        \"impact_param\",\n",
    "        \"orbital_period\",\n",
    "        \"albedo\",\n",
    "        \"transit_time\",\n",
    "    ]\n",
    "\n",
    "    keys_db = [\n",
    "        \"Planet Mass or Mass*sin(i) [Jupiter Mass]\",\n",
    "        \"Planet Radius [Jupiter Radius]\",\n",
    "        'Orbit Semi-Major Axis [au])',\n",
    "        'Impact Parameter',\n",
    "        'Orbital Period [days]',\n",
    "        \"NO MATCHING KEY\",\n",
    "        'Transit Duration [hours]',\n",
    "    ]\n",
    "\n",
    "    planet_dict = {\"planet_type\": \"simple\"}\n",
    "\n",
    "    for k1, k2 in zip(keys_header, keys_db):\n",
    "        try:\n",
    "            v = target[k2]\n",
    "            assert isinstance(v, float) and np.isfinite(v)\n",
    "            planet_dict[k1] = v\n",
    "        except (KeyError, AssertionError):\n",
    "            pass\n",
    "\n",
    "    return {\"Planet\": {**planet_dict, **settings}}\n",
    "\n",
    "\n",
    "def make_Star_dict(target=None, settings=None, **kwargs):\n",
    "    if target is None:\n",
    "        raise ValueError\n",
    "    # TODO: PHOENIX library normally used?\n",
    "    if settings is None:\n",
    "        settings = {}\n",
    "\n",
    "    keys_header =[\n",
    "        \"temperature\",\n",
    "        \"radius\",\n",
    "        \"mass\",\n",
    "        \"distance\",\n",
    "        \"metallicity\",\n",
    "        \"magnitudeK\",\n",
    "    ]\n",
    "\n",
    "    keys_db = [\n",
    "        'Stellar Effective Temperature [K]',\n",
    "        'Stellar Radius [Solar Radius]',\n",
    "        'Stellar Mass [Solar mass]',\n",
    "        'Distance [pc]',\n",
    "        'Stellar Metallicity Ratio',\n",
    "        'Ks (2MASS) Magnitude',\n",
    "    ]\n",
    "\n",
    "    solar_metallicity = 0.0196\n",
    "\n",
    "    star_dict = {\"star_type\": \"blackbody\"}\n",
    "\n",
    "    for k1, k2 in zip(keys_header, keys_db):\n",
    "        try:\n",
    "            v = target[k2]\n",
    "            assert isinstance(v, float) and np.isfinite(v)\n",
    "            if k1 == \"metallicity\" or k2 == 'Stellar Metallicity Ratio':\n",
    "                star_dict[k1] = v / solar_metallicity\n",
    "                continue\n",
    "            star_dict[k1] = v\n",
    "        except (KeyError, AssertionError):\n",
    "            pass\n",
    "\n",
    "    return {\"Star\": {**star_dict, **settings}}\n",
    "\n",
    "\n",
    "def make_FW_dict(target=None, settings=None, **kwargs):\n",
    "    if target is None:\n",
    "        raise ValueError\n",
    "    if settings is None:\n",
    "        settings = {}\n",
    "\n",
    "    model_dict = {\n",
    "        \"model_type\": \"transmission\",\n",
    "        \"Absorption\": {},\n",
    "        \"CIA\": {\"cia_pairs\": ['H2-H2', 'H2-He']},\n",
    "        \"Rayleigh\": {},\n",
    "        # \"SimpleClouds\": {\"clouds_pressure\": 0.1}, # OR:\n",
    "        # \"ThickClouds\": {\"clouds_pressure\": 0.1},\n",
    "        # \"LeeMie\": {},  # OR:\n",
    "        # 'BHMie': {},  # OR:\n",
    "        # \"FlatMie\": {},\n",
    "    }\n",
    "\n",
    "    return {\"Model\": {**model_dict, **settings}}\n",
    "\n",
    "\n",
    "def make_Fit_dict(tm=None, target=None, which=None, settings=None, default=False, **kwargs):\n",
    "    if target is None:\n",
    "        raise ValueError\n",
    "\n",
    "    if (tm is None and which is None) and not default:\n",
    "        raise ValueError(f\"tm is not defined yet, cannot set fitting dict without 'which': {which}\")\n",
    "\n",
    "    if settings is None:\n",
    "        settings = {}\n",
    "\n",
    "    if tm is not None:\n",
    "        possible_fit_para = [k for k, v in tm.fittingParameters.items()]\n",
    "        if which is None:\n",
    "            which = possible_fit_para\n",
    "    elif tm is None and default:\n",
    "        which = [\n",
    "            \"planet_radius\",\n",
    "            \"T_irr\",\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "    default_fit_para = {\n",
    "        \"planet_mass\" : {\n",
    "            \"fit\": False,\n",
    "            \"bounds\": [np.nan, np.nan],\n",
    "            \"prior\": \"Uniform(bounds=({}, {}))\",\n",
    "            \"value\": target[\"Planet Mass or Mass*sin(i) [Jupiter Mass]\"]\n",
    "        },\n",
    "        \"planet_radius\" : {\n",
    "            \"fit\": True,\n",
    "            \"bounds\": [0.5, 2.2],\n",
    "            \"prior\": \"Uniform(bounds=({}, {}))\",\n",
    "            \"value\": target[\"Planet Radius [Jupiter Radius]\"]\n",
    "        },\n",
    "        # \"planet_distance\" : {\n",
    "        #     \"fit\": True,\n",
    "        #     \"bounds\": [],\n",
    "        #     \"prior\": \"Uniform(bounds=({}, {}))\"\n",
    "        # },\n",
    "        # \"planet_sma\" : {\n",
    "        #     \"fit\": True,\n",
    "        #     \"bounds\": [],\n",
    "        #     \"prior\": \"Uniform(bounds=({}, {}))\"\n",
    "        # },\n",
    "        \"T\" : {\n",
    "            \"fit\": True,\n",
    "            \"bounds\": [500, 3500],\n",
    "            \"prior\": \"Uniform(bounds=({}, {}))\",\n",
    "            \"value\": target[\"Equilibrium Temperature [K]\"]\n",
    "        },\n",
    "        \"T_irr\" : {\n",
    "            \"fit\": True,\n",
    "            \"bounds\": [500, 3500],\n",
    "            \"prior\": \"Uniform(bounds=({}, {}))\",\n",
    "            \"value\": target[\"Equilibrium Temperature [K]\"]\n",
    "        },\n",
    "        \"atm_min_pressure\" : {\n",
    "            \"fit\": False,\n",
    "            \"bounds\": [1e-8, 1e-2],\n",
    "            \"prior\": \"LogUniform(lin_bounds=({}, {}))\",\n",
    "            \"value\": 1e-4,\n",
    "        },\n",
    "        \"atm_max_pressure\" : {\n",
    "            \"fit\": False,\n",
    "            \"bounds\": [1e4, 1e8],\n",
    "            \"prior\": \"LogUniform(lin_bounds=({}, {}))\",\n",
    "            \"value\": 1e6\n",
    "        },\n",
    "        \"nlayers\" : {\n",
    "            \"fit\": False,\n",
    "            \"bounds\": [np.nan, np.nan],\n",
    "            \"prior\": \"Uniform(bounds=({}, {}))\",\n",
    "            \"value\": 100\n",
    "        },\n",
    "    }\n",
    "\n",
    "    fit_dict = {}\n",
    "\n",
    "    for para in which:\n",
    "        try:\n",
    "            assert para in possible_fit_para.keys(), f\"Cant fit {para} because it is not in the possible fitting parameters: {possible_fit_para}\"\n",
    "        except UnboundLocalError as e:\n",
    "            if default:\n",
    "                pass\n",
    "            else:\n",
    "                raise e\n",
    "        assert para in default_fit_para.keys(), f\"Cant fit {para} because it is not in the default fitting parameter: {default_fit_para.keys()}. Ignore this if the fit is set elsewhere.\"\n",
    "        try:\n",
    "\n",
    "            value = default_fit_para[para][\"value\"]\n",
    "\n",
    "            # check for violated bounds\n",
    "            if value < default_fit_para[para][\"bounds\"][0]:\n",
    "                default_fit_para[para][\"bounds\"][0] = 0.5 * value\n",
    "            if value > default_fit_para[para][\"bounds\"][1]:\n",
    "                default_fit_para[para][\"bounds\"][1] = 2 * value\n",
    "\n",
    "            para_fit_dict = {\n",
    "                f'{para}:fit': default_fit_para[para][\"fit\"],\n",
    "                f'{para}:prior': default_fit_para[para][\"prior\"].format(*default_fit_para[para][\"bounds\"]),\n",
    "            }\n",
    "\n",
    "            fit_dict = {**fit_dict, **para_fit_dict}\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    return {\"Fitting\": {**fit_dict, **settings}}\n",
    "\n",
    "\n",
    "def make_bounds_from_derived_para(para, *args, interval=None, mode=None, fit=True, **kwargs):\n",
    "    if interval is None:\n",
    "        interval = np.array([0.1, 10.])\n",
    "    if mode is None:\n",
    "        mode = \"linear\" # TODO: check with docs if custom priors instead of bounds\n",
    "\n",
    "    out = {\n",
    "        f\"{para['name']}:fit\": fit,\n",
    "        f\"{para['name']}:bounds\": list(np.sort(interval * para[\"value\"])),\n",
    "        f\"{para['name']}:mode\": mode,\n",
    "    }\n",
    "\n",
    "    return {\"Fitting\": out}\n",
    "\n",
    "mode_dict = {\n",
    "    \"linear\": \"Uniform(bounds=({}, {}))\",\n",
    "    \"log\": \"LogUniform(lin_bounds=({}, {}))\",\n",
    "}\n",
    "\n",
    "def make_prior_from_bounds_mode(bounds, mode):\n",
    "\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def make_Derive_dict():\n",
    "    derive_dict = {\n",
    "        \"mu:compute\": True,\n",
    "        \"logg:compute\": True,\n",
    "        \"avg_T:compute\": True,\n",
    "        \"C_O_ratio:compute\": True,\n",
    "        \"He_H_ratio:compute\": True,\n",
    "    }\n",
    "\n",
    "    return {\"Derive\":  derive_dict}\n",
    "\n",
    "\n",
    "def unpack_dicts(dicts, ignore_keys=None, ignore_overwrite=False):\n",
    "    if ignore_keys is None:\n",
    "        ignore_keys = []\n",
    "\n",
    "    def _unpack_dict(d, out_dict):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                if k not in out_dict:\n",
    "                    out_dict[k] = {}\n",
    "                _unpack_dict(v, out_dict[k])\n",
    "            elif k in out_dict and (k not in ignore_keys or ignore_overwrite) :\n",
    "                raise ValueError(f\"Overwriting non-dict value for key '{k}'\")\n",
    "            else:\n",
    "                out_dict[k] = v\n",
    "        return out_dict\n",
    "\n",
    "    out_dict = {}\n",
    "    for d in dicts:\n",
    "        out_dict = _unpack_dict(d, out_dict)\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "def write_par_file(path_list, target, tm=None):\n",
    "    global_dict = make_Global_dict()\n",
    "    obs_dict = make_Obs_ObsFit_dict(path_list=path_list)\n",
    "    chem_dict = make_Chem_dict()\n",
    "    temp_dict = make_Temp_dict(target=target)\n",
    "    press_dict = make_Press_dict()\n",
    "    planet_dict = make_Planet_dict(target=target)\n",
    "    star_dict = make_Star_dict(target=target)\n",
    "    fw_dict = make_FW_dict(target=target)\n",
    "    fit_dict = make_Fit_dict(tm=tm, target=target, default=True)\n",
    "\n",
    "    dict_list = [\n",
    "        global_dict,\n",
    "        obs_dict,\n",
    "        chem_dict,\n",
    "        temp_dict,\n",
    "        press_dict,\n",
    "        planet_dict,\n",
    "        star_dict,\n",
    "        fw_dict,\n",
    "        fit_dict,\n",
    "    ]\n",
    "\n",
    "    par_dict = unpack_dicts(dict_list)\n",
    "\n",
    "    config = TaurexConfigObj(par_dict)\n",
    "    path = str(WDIR / \"data/test.par\")\n",
    "    config.filename = path\n",
    "    config.initial_comment.append(f'# Created: {datetime.now().isoformat(sep=\"-\", timespec=\"seconds\").replace(\":\", \"-\")}')\n",
    "    config.write()\n",
    "\n",
    "\n",
    "path_list = [\n",
    "    str(WDIR / \"data/taurex_lightcurves_LW\" / \"HAT-P-1-b_HST_STIS_G430L_52X2_Nikolov+2014.txt\"),\n",
    "    str(WDIR / \"data/taurex_lightcurves_LW\" / \"HAT-P-1-b_HST_STIS_G430L_52X2_Sing+2016.txt\"),\n",
    "]\n",
    "\n",
    "target = get_target_data(\"HAT-P-1 b\")\n",
    "\n",
    "write_par_file(path_list, target=target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12-15-55-35\n"
     ]
    }
   ],
   "source": [
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New directory created: /data/retrievals\\Mars\\SOFIA\\FORCAST\\Mars_SOFIA_FORCAST(aperture-3x3_source-Solar_spectral_element-25.0um)(aperture-3x3_source-Nadir_spectral_element-25.0um)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_directory(parsed_data):\n",
    "    common_keys = ['planet_name', 'facility', 'instrument']\n",
    "\n",
    "    # Determine common properties and varying properties for each entry\n",
    "    common_properties = {key: parsed_data[0][key] for key in common_keys}\n",
    "    varying_properties = [sorted({key: entry[key] for key in entry.keys() if key not in common_keys}.items()) for entry in parsed_data]\n",
    "\n",
    "    # Format the varying properties as strings\n",
    "    varying_properties_str = []\n",
    "    for vp in varying_properties:\n",
    "        vp_str = [f\"{key}-{value}\" for key, value in vp if key not in common_properties]\n",
    "        varying_properties_str.append(f\"({'_'.join(vp_str)})\")\n",
    "\n",
    "    # Create the new directory name\n",
    "    new_dir_name = f\"{common_properties['planet_name']}_{common_properties['facility']}_{common_properties['instrument']}{''.join(varying_properties_str)}\"\n",
    "\n",
    "    # Create the directory path\n",
    "    base_path = \"/data/retrievals\"\n",
    "    dir_path = os.path.join(base_path, common_properties['planet_name'], common_properties['facility'], common_properties['instrument'], new_dir_name)\n",
    "\n",
    "    # Create the directory\n",
    "    # os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    return dir_path\n",
    "\n",
    "\n",
    "parsed_data = [\n",
    "    {\n",
    "        'planet_name': 'Mars',\n",
    "        'facility': 'SOFIA',\n",
    "        'instrument': 'FORCAST',\n",
    "        'spectral_element': '25.0um',\n",
    "        'aperture': '3x3',\n",
    "        'source': 'Solar',\n",
    "    },\n",
    "    {\n",
    "        'planet_name': 'Mars',\n",
    "        'facility': 'SOFIA',\n",
    "        'instrument': 'FORCAST',\n",
    "        'spectral_element': '25.0um',\n",
    "        'aperture': '3x3',\n",
    "        'source': 'Nadir',\n",
    "    }\n",
    "]\n",
    "\n",
    "dir_path = create_directory(parsed_data)\n",
    "print(f\"New directory created: {dir_path}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instrument': ['STIS', 'WFC3'], 'aperture': ['NA', 'APP2', 'APP1'], 'bandwidth': ['NA', 'False', 'True'], 'source': ['NA', 'S2', 'S1'], 'facility': ['HST', 'JWST'], 'spectral_element': 'G141', 'planet_name': 'P'}\n",
      "\\data\\retrievals\\P\\new_directory\n",
      "P_G141_facility(HST_JWST)_instrument(STIS_WFC3)_aperture(NA_APP2_APP1)_bandwidth(NA_False_True)_source(NA_S2_S1)\n"
     ]
    }
   ],
   "source": [
    "def merge_dicts(dict_list):\n",
    "    merged_dict = {}\n",
    "\n",
    "    all_keys = set().union(*(d.keys() for d in dict_list))\n",
    "\n",
    "    for key in all_keys:\n",
    "        values = [d.get(key, \"NA\") for d in dict_list]\n",
    "        unique_values = list(set(values))\n",
    "\n",
    "        if len(unique_values) == 1:\n",
    "            merged_dict[key] = unique_values[0]\n",
    "        else:\n",
    "            merged_dict[key] = unique_values\n",
    "\n",
    "    return merged_dict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def create_path(merged_dict):\n",
    "    base_path = Path(\"/data/retrievals\")\n",
    "    keys_in_order = ['planet_name', 'facility', 'instrument', 'spectral_element']\n",
    "\n",
    "    common_keys = []\n",
    "    for key in keys_in_order:\n",
    "        if isinstance(merged_dict[key], list):\n",
    "            break\n",
    "        common_keys.append(key)\n",
    "\n",
    "    new_directory = \"new_directory\"\n",
    "    path_parts = [base_path] + [merged_dict[key] for key in common_keys] + [new_directory]\n",
    "    path = Path(*path_parts)\n",
    "\n",
    "    return path\n",
    "\n",
    "def create_filename(merged_dict):\n",
    "    keys_in_order = ['planet_name', 'facility', 'instrument', 'spectral_element']\n",
    "    not_common_keys = [key for key in merged_dict if key not in keys_in_order]\n",
    "\n",
    "    if isinstance(merged_dict['planet_name'], list):\n",
    "        raise ValueError(\"Planet name must be common among all entries\")\n",
    "\n",
    "    common_part = '_'.join([merged_dict[key] for key in keys_in_order if not isinstance(merged_dict[key], list)])\n",
    "    not_common_part = '_'.join([f\"{key}(\" + '_'.join([f\"{value}\" for value in merged_dict[key]]) + \")\" for key in keys_in_order + not_common_keys if isinstance(merged_dict[key], list)])\n",
    "\n",
    "    filename = f\"{common_part}_{not_common_part}\"\n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "file_data1 = {\n",
    "    'planet_name': \"P\",\n",
    "    'facility': \"HST\",\n",
    "    'instrument': \"STIS\",\n",
    "    'spectral_element': \"G141\",\n",
    "    'aperture': \"APP1\",\n",
    "    'source': \"S1\",\n",
    "    'bandwidth': \"True\"\n",
    "}\n",
    "\n",
    "file_data2 = {\n",
    "    'planet_name': \"P\",\n",
    "    'facility': \"HST\",\n",
    "    'instrument': \"STIS\",\n",
    "    'spectral_element': \"G141\",\n",
    "}\n",
    "\n",
    "file_data3 = {\n",
    "    'planet_name': \"P\",\n",
    "    'facility': \"JWST\",\n",
    "    'instrument': \"WFC3\",\n",
    "    'spectral_element': \"G141\",\n",
    "    'aperture': \"APP2\",\n",
    "    'source': \"S2\",\n",
    "    'bandwidth': \"False\"\n",
    "}\n",
    "\n",
    "proplist = [file_data1, file_data2, file_data3]\n",
    "\n",
    "merged = merge_dicts(proplist)\n",
    "\n",
    "print(merged)\n",
    "\n",
    "path = create_path(merged)\n",
    "\n",
    "print(path)\n",
    "\n",
    "filename = create_filename(merged)\n",
    "print(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('/data/retrievals/P/HST/STIS/new_directory')"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}