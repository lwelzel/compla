{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pprint\n",
    "import warnings\n",
    "from pandas.errors import ParserWarning\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import List, Dict, Tuple, Any, Union, Callable\n",
    "from astropy.table import Table, MaskedColumn\n",
    "\n",
    "from astroquery import mast\n",
    "from astroquery.mast import Observations\n",
    "from astropy.time import Time, TimeJD, TimeDelta\n",
    "from astroquery.mast.missions import MastMissions\n",
    "hst_mission = MastMissions(mission='hst')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [7, 7]\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# local setup\n",
    "WDIR = Path().cwd().parent\n",
    "\n",
    "EMISSION_DATABASE_PATH = WDIR / \"data/emissionspec.csv\"\n",
    "TRANSMISSION_DATABASE_PATH = WDIR / \"data/transitspec.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def alias_this(s: str):\n",
    "    alias_dict = {\n",
    "        \"Wide Field Camera 3\": \"WFC3\",\n",
    "        \"Space Telescope Imaging Spectrograph\": \"STIS\",\n",
    "        \"Hubble Space Telescope satellite\": \"HST\",\n",
    "        \"Hubble Space Telescope\": \"HST\",\n",
    "        # Add more aliases as necessary\n",
    "    }\n",
    "    if s in alias_dict:\n",
    "        return alias_dict[s]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def extract_abbreviation(string, force_abbrv=False):\n",
    "    match = re.search(r'\\(([A-Z]+)\\)', string)\n",
    "    if match:\n",
    "        abbrv = match.group(1)\n",
    "        abbrv = re.sub(r'[\\[\\]()]', '', abbrv)\n",
    "        return abbrv\n",
    "    elif force_abbrv:\n",
    "        words = string.split()\n",
    "        abbrv = \"\"\n",
    "        for word in words:\n",
    "            abbrv += word[0].upper()\n",
    "        abbrv = re.sub(r'[\\[\\]()]', '', abbrv)\n",
    "        return abbrv\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "def append_next_string(first_list: List[str], second_list: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function takes in a list of strings and appends the next string in another\n",
    "    list of strings that is not already in the first list. It returns the first list with the appended string.\n",
    "\n",
    "    Args:\n",
    "    - first_list: A list of strings.\n",
    "    - second_list: Another list of strings.\n",
    "\n",
    "    Returns:\n",
    "    - A list of strings that contains all the strings in the first list and the next string in the\n",
    "      second list that is not already in the first list.\n",
    "    \"\"\"\n",
    "    for string in second_list:\n",
    "        if string not in first_list:\n",
    "            first_list.append(string)\n",
    "            break\n",
    "\n",
    "    return first_list\n",
    "\n",
    "default_warning_filters = [\n",
    "    {\"category\":DeprecationWarning, \"module\":''},\n",
    "    {\"category\":FutureWarning, \"module\":''},\n",
    "    {\"category\":RuntimeWarning, \"module\":''},\n",
    "    {\"category\":Warning, \"module\":'numpy'},\n",
    "    {\"category\":Warning, \"module\":'scipy'},\n",
    "    {\"category\":Warning, \"module\":'pandas'},\n",
    "    {\"category\":Warning, \"module\":'astropy'},\n",
    "    {\"category\":Warning, \"module\":'astroquery'},\n",
    "]\n",
    "\n",
    "def run_function_with_warnings_filtered(func: Callable[..., Any], *args: Tuple[Any], filters: (List[Dict[str, Any]], None)=None, verbose: bool=True, **kwargs: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Executes the input function while filtering warnings as specified by the filters list.\n",
    "\n",
    "    Args:\n",
    "        func (Callable[..., Any]): The function to be executed.\n",
    "        filters (List[Dict[str, Any]]): A list of dictionaries containing the warning category and module to be filtered.\n",
    "        *args (Tuple[Any]): Positional arguments to be passed to the input function.\n",
    "        verbose (bool, optional): If True, prints the warnings after the function execution. Defaults to True.\n",
    "        **kwargs (Any): Keyword arguments to be passed to the input function.\n",
    "\n",
    "    Returns:\n",
    "        Any: The result of the executed input function.\n",
    "    \"\"\"\n",
    "    if filters is None:\n",
    "        filters = []\n",
    "\n",
    "    # Create a filter that includes warnings from all relevant modules\n",
    "    all_warnings = []\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        filters = default_warning_filters + filters\n",
    "        for f in filters:\n",
    "            warnings.filterwarnings(\"ignore\", **f)\n",
    "\n",
    "        # Call the input function with the provided *args and **kwargs\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        all_warnings.extend(w)\n",
    "\n",
    "    # print out the resulting warnings\n",
    "    if (verbose and len(all_warnings) > 0):\n",
    "        print(\"The following warnings were raised:\")\n",
    "        warns, idx, counts = np.unique([repr(w.message) for w in all_warnings], return_index=True, return_counts=True, )\n",
    "        warns = np.array(all_warnings, dtype=object)[idx]\n",
    "\n",
    "        for w, c in zip(warns, counts):\n",
    "            message_str = re.sub(r'^.*?(Warning\\()', r'\\1', str(w.message).rsplit('Warning(', 1)[-1], count=1)\n",
    "            print(f'Line: {w.lineno}, count: {c}: \\n'\n",
    "                  f'{pprint.pformat(message_str)}')\n",
    "    elif verbose:\n",
    "        print(\"No warnings were raised.\")\n",
    "\n",
    "    # Return the result of the function call\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_transmission = pd.read_csv(TRANSMISSION_DATABASE_PATH,\n",
    "                              header=26, index_col=0,\n",
    "                              dtype={\"plntranmid\": str, },\n",
    "                              )\n",
    "\n",
    "# fix time\n",
    "plntranmid = df_transmission[\"plntranmid\"].dropna(axis=\"index\")\n",
    "plntranmid_jd_time = pd.DataFrame(data=Time(plntranmid.to_numpy().astype(float), format=\"jd\"),\n",
    "                                  index=plntranmid.index, columns=[\"plntranmid_jd_time\"])\n",
    "plntranmid_jd_time[\"plntranmid_mjd_time\"] = [t.mjd for t in plntranmid_jd_time[\"plntranmid_jd_time\"]]\n",
    "df_transmission = df_transmission.join(plntranmid_jd_time, how=\"left\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def add_source_key(data_dict: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Adds source information to the input data dictionary by extracting the author(s) and year from the reflink.\n",
    "\n",
    "    Args:\n",
    "        data_dict (Dict): A dictionary containing data related to a planet observation.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The modified data dictionary with the added 'source', 'author', and 'year' keys.\n",
    "    \"\"\"\n",
    "    # Extract the plntranreflink value\n",
    "    reflink = data_dict.get('reflink', '')\n",
    "\n",
    "    # Search for the 'authoryear' pattern using a regular expression\n",
    "    pattern = re.compile(r'>(.+? et al\\. \\d{4})</a>|>(.+? \\d{4})</a>')\n",
    "    match = pattern.search(reflink)\n",
    "\n",
    "    author_pattern = re.compile(r'\\+\\d{4}$')\n",
    "    year_pattern = re.compile(r'\\d{4}')\n",
    "\n",
    "    if match:\n",
    "        authoryear = match.group(1) if match.group(1) else match.group(2)\n",
    "        if 'et al.' in authoryear:\n",
    "            authoryear = authoryear.replace(' et al. ', '+')\n",
    "\n",
    "        # Add the 'source' key with the extracted authoryear value\n",
    "        data_dict['source'] = authoryear.strip()\n",
    "        data_dict['author'] = re.sub(author_pattern, '',  data_dict['source'])\n",
    "        year_match = re.search(year_pattern, data_dict['source'])\n",
    "        data_dict['year'] = int(year_match.group(0)) if match else None\n",
    "    else:\n",
    "        data_dict['source'] = None\n",
    "        data_dict['author'] = None\n",
    "        data_dict['year'] = None\n",
    "\n",
    "    data_dict[\"data\"]['prelim_group_id'] = data_dict['prelim_group_id']\n",
    "    data_dict[\"data\"]['source'] = data_dict['source']\n",
    "    data_dict[\"data\"]['author'] = data_dict['author']\n",
    "    data_dict[\"data\"]['year'] = data_dict['year']\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def extract_data(df: pd.DataFrame) -> List[Dict]:\n",
    "    # Group the DataFrame by unique combinations of planet_name, instrument, facility, and reflink\n",
    "    grouped = df.groupby(['plntname', 'facility', 'instrument', 'plntranreflink'])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i, ((planet_name, facility, instrument, reflink), group) in enumerate(grouped):\n",
    "        # Convert each group to a dictionary\n",
    "        entry = {\n",
    "            'plntname': planet_name,\n",
    "            'facility': facility,\n",
    "            'instrument': instrument,\n",
    "            'reflink': reflink,\n",
    "            \"prelim_group_id\": i,\n",
    "            'data': group\n",
    "        }\n",
    "\n",
    "        # Add the entry to the result list\n",
    "        entry = add_source_key(entry)\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "    return result\n",
    "\n",
    "def concat_specs(dicts_list):\n",
    "    dfs = [d['data'] for d in dicts_list]\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "split_transmission = extract_data(df_transmission)\n",
    "spec_transmission = concat_specs(split_transmission)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique planets with transmission spectra: 103.\n",
      "\tMedian count: 2.0, mean count: 2.0 +/- 3.8, max count: 21 (GJ 1214 b).\n",
      "Summary:\n",
      "  spectra:\n",
      "    346\n",
      "  plntname:\n",
      "    4 x 55 Cnc e, GJ 1132 b, HAT-P-3 b, K2-18 b, WASP-31 b, WASP-46 b, WASP-57 b, WASP-67 b, WASP-74 b, WASP-79 b\n",
      "    2 x CoRoT-1 b, GJ 436 b, HAT-P-18 b, HAT-P-23 b, K2-26 b, K2-3 b, K2-3 c, K2-3 d, KELT-9 b, KOI-12 b, KOI-13 b, KOI-94 d, Kepler-10 c, Kepler-102 d, Kepler-102 e, Kepler-104 d, Kepler-11 e, Kepler-125 b, Kepler-126 d, Kepler-127 d, Kepler-138 c, Kepler-14 b, Kepler-158 c, Kepler-18 c, Kepler-18 d, Kepler-19 b, Kepler-20 c, Kepler-20 d, Kepler-205 c, Kepler-22 b, Kepler-236 c, Kepler-249 d, Kepler-25 b, Kepler-25 c, Kepler-26 c, Kepler-32 d, Kepler-37 d, Kepler-410 A b, Kepler-49 b, Kepler-49 c, Kepler-61 b, Kepler-62 e, Kepler-68 b, Kepler-93 b, Kepler-94 b, WASP-107 b, WASP-121 b, WASP-21 b, WASP-52 b, XO-1 b\n",
      "    21 x GJ 1214 b, GJ 3470 b\n",
      "    7 x HAT-P-1 b, HAT-P-32 b, WASP-12 b, WASP-17 b, WASP-43 b, WASP-80 b\n",
      "    3 x HAT-P-11 b, KELT-11 b, TrES-3 b, WASP-103 b, WASP-127 b, WASP-4 b, WASP-45 b, WASP-48 b\n",
      "    11 x HAT-P-12 b\n",
      "    5 x HAT-P-14 b, HAT-P-26 b, HD 209458 b, XO-2 N b\n",
      "    1 x HAT-P-16 b, HAT-P-19 b, HAT-P-41 b, HAT-P-7 b, HD 97658 b, Qatar-1 b, TRAPPIST-1 g, TrES-2 b, TrES-4 b, WASP-101 b, WASP-117 b, WASP-14 b, WASP-29 b, WASP-33 b, WASP-6 b, WASP-69 b, WASP-76 b, WASP-96 b, WASP-98 b\n",
      "    20 x HD 189733 b\n",
      "    12 x WASP-19 b\n",
      "    16 x WASP-39 b\n",
      "  facility:\n",
      "    70 x HSTS, SSTS\n",
      "    5 x NOT, MILCT, LBTO, MO\n",
      "    1 x ITF, CIS, CT, KIT, L1TASAAO, L2TAHO, L2TASSO, LO1NT, LO4DCT, TNO2T, GRANTECAN, TNG, FTN, L2MTAODRDLM, KPNO, NOAO, GGNT, SOFIA, CAO3MT, LBT, HST, TVLT, FTS, GST, OAN2T, SOAR, AURA, SMARTS, OANHJT, ODT0MT, NTT, C1T, TESS, INGWHT, NOAO\n",
      "    12 x MPG2MTAESO\n",
      "    10 x GTC1T\n",
      "    2 x ISF, INGINT, TSART, L1TACTIO, L1TAMO, AOCT, SRO, UNAM, UDEM, AURA, NTT, OAN0T\n",
      "    6 x INGWHT, VLT, TSE1T\n",
      "    3 x LSO6TT, MIWBT, FLWO1MT, CAO1MT\n",
      "    4 x NAOOJOAO1T, SO1MKT, CAO2MT, ESO3MT\n",
      "    42 x TKM\n",
      "    9 x JWST\n",
      "    8 x D1TAESO\n",
      "  instrument:\n",
      "    44 x WFC3\n",
      "    3 x ALFOSC, LDSS-3C, T, IS, ISLE, Mont4k CCD, DC\n",
      "    67 x IRAC\n",
      "    4 x WFC3, SI, BUSCA, HES\n",
      "    1 x SAM, PISCO, WIRCam, LIRIS, NOTCam, FORS, MOSFIRE, CDIC, LMI, MCI, ULTRASPEC, DOLORES, MODS2, StanCam, SC, RISE, MuSCAT, CCD camera, FLAMINGOS, KeplerCam, ACFS, IRAC, MIPS, HIPO, IRAC, CARMENES, PEPSI, GIRAFFE, DI, M2, NIC, NIS-EP, NIS-FP, NIS-G, NIS-P, NIS-TP, NIS-TP, MC, Y4KCam, Sinistro, RATIR, CAMELOT, BFOSC, TCA, KOSMOS\n",
      "    12 x GROND, OSIRIS\n",
      "    2 x SIRIUS, WFC, LBC, MMIRS, SOI, FCB, KCC, AFOSC, Keplercam, MODS1, WiFSIP, NIRISS, MEXMAN, SS, ULTRACAM, EFOSC2, Mexman\n",
      "    5 x ACAM, MI, GMOS, NICAMS, FORS2\n",
      "    17 x STIS\n",
      "    6 x EulerCam\n",
      "    40 x KCA\n",
      "    7 x DFOSC\n"
     ]
    }
   ],
   "source": [
    "def unique_planets_and_counts(dict_list: List[Dict]) -> (List[str], List[float]):\n",
    "    planet_counts = {}\n",
    "\n",
    "    for item in dict_list:\n",
    "        planet_name = item['plntname']\n",
    "        if planet_name in planet_counts:\n",
    "            planet_counts[planet_name] += 1\n",
    "        else:\n",
    "            planet_counts[planet_name] = 1\n",
    "\n",
    "    unique_planet_names = list(planet_counts.keys())\n",
    "    counts = list(planet_counts.values())\n",
    "\n",
    "    return unique_planet_names, counts\n",
    "\n",
    "# TODO: write regex that checks for number of star systems: all non-special characters must be equal except for the letter at the last position.\n",
    "\n",
    "def summarize_spectra(spectra_dicts: List[Dict[str, str]], verbose: bool = True) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Summarize the input list of dictionaries by counting occurrences of specific elements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectra_dicts : List[Dict[str, str]]\n",
    "        A list of dictionaries containing specific elements.\n",
    "    verbose : bool, optional\n",
    "        If True, print the summary, default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, int]\n",
    "        A dictionary with the counts of specific elements in the input list.\n",
    "    \"\"\"\n",
    "    # Initialize the output dictionary\n",
    "    summary = {}\n",
    "\n",
    "    # Find the number of spectra in the input\n",
    "    summary['spectra'] = len(spectra_dicts)\n",
    "\n",
    "    # Define columns for counting occurrences\n",
    "    count_columns = ['plntname', 'facility', 'instrument']\n",
    "\n",
    "    # Count occurrences for each element in count_columns\n",
    "    for column in count_columns:\n",
    "        summary[column] = {}\n",
    "        for d in spectra_dicts:\n",
    "            key = d[column]\n",
    "            summary[column][key] = summary[column].get(key, 0) + 1\n",
    "\n",
    "    # Print the summary if verbose is True\n",
    "    if verbose:\n",
    "        print(\"Summary:\")\n",
    "        for key, value in summary.items():\n",
    "            print(f\"  {key}:\")\n",
    "            if isinstance(value, dict):\n",
    "                inverted = {}\n",
    "                for k, v in value.items():\n",
    "                    if v not in inverted:\n",
    "                        inverted[v] = [k]\n",
    "                    else:\n",
    "                        inverted[v].append(k)\n",
    "\n",
    "                for count, items in inverted.items():\n",
    "                    if key in ['facility', 'instrument']:\n",
    "                        print(f\"    {count} x {', '.join([extract_abbreviation(item, force_abbrv=True) if len(item) > 10  else extract_abbreviation(item, force_abbrv=False) for item in items])}\")\n",
    "                    else:\n",
    "                        print(f\"    {count} x {', '.join(items)}\")\n",
    "            else:\n",
    "                print(f\"    {value}\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "all_planets, counts = unique_planets_and_counts(split_transmission)\n",
    "\n",
    "print(f\"Number of unique planets with transmission spectra: {len(all_planets)}.\\n\"\n",
    "      f\"\\tMedian count: {np.median(counts)}, mean count: {np.median(counts):.1f} +/- {np.std(counts):.1f}, max count: {np.max(counts)} ({all_planets[np.argmax(counts)]}).\")\n",
    "\n",
    "summary = summarize_spectra(split_transmission)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_count_elements(column: MaskedColumn):\n",
    "    \"\"\"Return the most frequent element in the given Astropy MaskedColumn.\"\"\"\n",
    "    if isinstance(column, MaskedColumn):\n",
    "        column = column.filled(np.nan)\n",
    "\n",
    "    mode, counts = stats.mode(column, nan_policy=\"omit\")\n",
    "    return mode.flatten(), counts.flatten()\n",
    "\n",
    "def check_time_window(table: Table, value: float) -> (bool, np.ndarray):\n",
    "    \"\"\"Return an array indicating if the float is between two column values for each row.\"\"\"\n",
    "    col1, col2 = table[table.colnames[0]], table[table.colnames[1]]\n",
    "\n",
    "    col1, col2 = Time(np.array(col1), format='isot', scale='utc'), Time(np.array(col2), format='isot', scale='utc')\n",
    "\n",
    "    if value == np.nan:\n",
    "        return False, []\n",
    "    else:\n",
    "        value = Time(value, format=\"mjd\")\n",
    "        delta1, delta2 = col1 - value, col2 - value\n",
    "        return True, np.unique([np.argwhere(delta1.isclose(TimeDelta(0., format=\"sec\"), atol=TimeDelta(600, format=\"sec\"))), np.argwhere(delta2.isclose(TimeDelta(0., format=\"sec\"), atol=TimeDelta(600, format=\"sec\")))])\n",
    "\n",
    "def check_wavelength_window(table: Table, value: float, scale: float) -> (bool, np.ndarray):\n",
    "    \"\"\"Return an array indicating if the float is between two column values for each row.\"\"\"\n",
    "    col1, col2 = table[table.colnames[0]], table[table.colnames[1]]\n",
    "\n",
    "    col1, col2 = np.array(col1, dtype=float), np.array(col2, dtype=float)\n",
    "\n",
    "    if value == np.nan:\n",
    "        return False, []\n",
    "    else:\n",
    "        delta1, delta2 = np.abs(col1 - value * scale), np.abs(col2 - value * scale)\n",
    "        return True, np.unique([delta1.argmin(), delta2.argmin()])\n",
    "\n",
    "def check_central_wavelength(col: MaskedColumn, value: float, scale: float) -> (bool, np.ndarray):\n",
    "    \"\"\"Return an array indicating if the float is close to the column values for each row.\"\"\"\n",
    "\n",
    "    col = np.array(col, dtype=float)\n",
    "\n",
    "    if value == np.nan:\n",
    "        return False, []\n",
    "    else:\n",
    "        delta1 = np.abs(col - value * scale)\n",
    "        return True, np.argwhere(np.isclose(delta1, 0., atol=10., rtol=0.)).flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def assign_spec_element_to_obs(obs: pd.Series, results: pd.DataFrame, planet_name: str, instrument: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Assigns the spectral element and aperture to the given observation based on the given results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : pd.Series\n",
    "        A pandas Series containing the observation data.\n",
    "    results : pd.DataFrame\n",
    "        A pandas DataFrame containing the results data.\n",
    "    planet_name : str\n",
    "        The name of the planet for the observation.\n",
    "    instrument : str\n",
    "        The name of the instrument used for the observation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        A pandas Series containing the assigned spectral element and aperture.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If a ValueError is encountered while processing the time windows.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Check if the observation is within the time window criteria\n",
    "    try:\n",
    "        time_match, t_window_crit = check_time_window(results[\"sci_start_time\", \"sci_stop_time\"], obs[\"plntranmid_mjd_time\"])\n",
    "    except ValueError:\n",
    "        t_window_crit = np.arange(len(results))\n",
    "\n",
    "    try:\n",
    "        assert (np.all(results['sci_aper_1234'] == results['sci_aper_1234'][0])\n",
    "                and np.all(results['sci_spec_1234'] == results['sci_spec_1234'][0]))\n",
    "        out =  pd.Series({\n",
    "                    'spectral_element': results['sci_spec_1234'][0],\n",
    "                    \"aperture\": results['sci_aper_1234'][0],\n",
    "                    \"spec_match_frac\": \"1/1\",\n",
    "                    \"aper_match_frac\": \"1/1\",\n",
    "                })\n",
    "    except AssertionError:\n",
    "        try:\n",
    "            assert (np.all(results['sci_aper_1234'][t_window_crit] == results['sci_aper_1234'][t_window_crit][0])\n",
    "                    and np.all(results['sci_spec_1234'][t_window_crit] == results['sci_spec_1234'][t_window_crit][0]))\n",
    "\n",
    "            out =  pd.Series({\n",
    "                'spectral_element': results['sci_spec_1234'][t_window_crit][0],\n",
    "                \"aperture\": results['sci_aper_1234'][t_window_crit][0],\n",
    "                \"spec_match_frac\": \"1/1\",\n",
    "                \"aper_match_frac\": \"1/1\",\n",
    "            })\n",
    "        except (IndexError,  AssertionError):\n",
    "            # Get the most frequent spectral element and aperture\n",
    "            if len(t_window_crit) > 1:\n",
    "                spec_mode, spec_count = get_count_elements(results['sci_spec_1234'][t_window_crit])\n",
    "                aper_mode, aper_count = get_count_elements(results['sci_aper_1234'][t_window_crit])\n",
    "            else:\n",
    "                spec_mode, spec_count = get_count_elements(results['sci_spec_1234'])\n",
    "                aper_mode, aper_count = get_count_elements(results['sci_aper_1234'])\n",
    "\n",
    "            spec_match_frac = f\"{np.sum(spec_count[0])}/{np.sum(spec_count)}\"\n",
    "            aper_match_frac = f\"{np.sum(aper_count[0])}/{np.sum(aper_count)}\"\n",
    "\n",
    "            if not (len(spec_mode)==1 and len(aper_mode)==1):\n",
    "            # Issue a warning about the inconsistency\n",
    "                warnings.warn(f\"{planet_name} - {instrument}:\\n\"\n",
    "                              f\"Could not find matching spectral element and aperture.\"\n",
    "                              f\"Spectral_element: {spec_mode[0]} ({spec_count[0] / np.sum(spec_count) * 100:.3f} % match, total: {np.sum(spec_count[0])}/{np.sum(spec_count)})\\n\"\n",
    "                              f\"Aperture:         {aper_mode[0]} ({aper_count[0] / np.sum(aper_count) * 100:.3f} % match, total: {np.sum(aper_count[0])}/{np.sum(aper_count)})\")\n",
    "\n",
    "            # Return the most frequent spectral element and aperture\n",
    "            out =  pd.Series({\n",
    "                'spectral_element': spec_mode[0],\n",
    "                \"aperture\": aper_mode[0],\n",
    "                \"spec_match_frac\": spec_match_frac,\n",
    "                \"aper_match_frac\": aper_match_frac,\n",
    "            })\n",
    "    finally:\n",
    "        if not 'out' in locals():\n",
    "            warnings.warn(f\"{planet_name} - {instrument} -  no valid match found in results after criteria relaxation.\")\n",
    "            out = pd.Series({\n",
    "                'spectral_element': \"NO VALID MATCH FAILURE\",\n",
    "                \"aperture\": \"NO VALID MATCH FAILURE\",\n",
    "                \"spec_match_frac\": \"0/0\",\n",
    "                \"aper_match_frac\": \"0/0\",\n",
    "            })\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "def get_mast_obs_data(spec: Dict[str, Any], pbar: Any=None, relax: (List[str], None)=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieves observation data from the MAST database for the given input specification and adds the data to the specification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec : Dict[str, Any]\n",
    "        A dictionary containing the input specification including planet name, facility, instrument, data, source, author, and year.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        The input specification with the retrieved observation data added.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    IndexError\n",
    "        If no matches are found in the MAST database for the given target and instrument.\n",
    "    \"\"\"\n",
    "\n",
    "    if relax is None:\n",
    "        relax = []\n",
    "\n",
    "    # Extract information from the input specification\n",
    "    planet_name = spec[\"plntname\"]\n",
    "    facility = spec[\"facility\"]\n",
    "    instrument = spec['instrument']\n",
    "    data = spec[\"data\"]\n",
    "\n",
    "    # TODO: remove: - Remove unnecessary keys from the data\n",
    "    drop_keys = [\"spectral_element\", \"aperture\"]\n",
    "    for key in drop_keys:\n",
    "        try:\n",
    "            spec[\"data\"].drop(key, axis=\"columns\", inplace=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    # Create target name and instrument aliases\n",
    "    target_name = re.sub(r'[a-z]$', '', planet_name).strip()\n",
    "    sci_targname = target_name + \"*,\" + (target_name.replace(' ', '-'))\n",
    "    instrument = alias_this(instrument) + \"*\"\n",
    "\n",
    "    relaxations = [\n",
    "        \"RELAX_sci_targname\",\n",
    "        \"RELAX_target\",\n",
    "        \"FAIL\",\n",
    "    ]\n",
    "    if \"FAIL\" in relax:\n",
    "        print(f\"FAILED: {target_name} - {sci_targname} - {instrument.lower()} - {relax}\")\n",
    "        warnings.warn (f\"No matches in {target_name} - {sci_targname} - {instrument.lower()}\")\n",
    "        spec[\"data\"][\"spectral_element\"] = \"NO MATCH FAILURE\"\n",
    "        spec[\"data\"][\"aperture\"] = \"NO MATCH FAILURE\"\n",
    "        return spec\n",
    "    if \"RELAX_sci_targname\" in relax:\n",
    "        sci_targname = \"*\"\n",
    "    if \"RELAX_target\" in relax:\n",
    "        # TODO: not implemented yet\n",
    "        target_name = target_name\n",
    "\n",
    "    # Query the MAST database for observation data\n",
    "    try:\n",
    "        results = hst_mission.query_criteria(\n",
    "            target=target_name,\n",
    "            sci_targname=sci_targname,\n",
    "            select_cols=[\n",
    "                'sci_targname',\n",
    "                'sci_instrume', 'sci_instrument_config', 'sci_aper_1234', 'sci_spec_1234',\n",
    "                'sci_central_wavelength', 'sci_spectrum_end', 'sci_spectrum_start', 'sci_bandwidth', 'sci_spectral_res',\n",
    "                'sci_preview_name', 'sci_refnum', 'sci_aec', 'sci_status', 'sci_data_set_name', 'sci_pi_last_name',\n",
    "                'sci_actual_duration', 'sci_start_time', 'sci_stop_time',\n",
    "            ],\n",
    "            sci_instrume=instrument.lower(),\n",
    "            sci_obs_type='all',\n",
    "            sci_aec='S',\n",
    "        )\n",
    "\n",
    "        # Handle cases where no matches are found\n",
    "        if len(results) == 0:\n",
    "            if isinstance(pbar, tqdm):\n",
    "                pbar.set_postfix_str(f\"Relaxing search for {target_name} - {sci_targname} - {instrument}\")\n",
    "            relax = append_next_string(relax, relaxations)\n",
    "            spec = get_mast_obs_data(spec, relax=relax)\n",
    "        else:\n",
    "            # Assign spectral element and aperture to the retrieved data\n",
    "            new = data.apply(assign_spec_element_to_obs, axis=\"columns\", args=(results, planet_name, instrument))\n",
    "            data = pd.concat([data, new], axis=1)\n",
    "\n",
    "            spec[\"data\"] = data\n",
    "\n",
    "    # Handle cases where no matches are found\n",
    "    except NotImplementedError:\n",
    "        print(f\"FAILED: {target_name} - {sci_targname} - {instrument.lower()} - {relax}\")\n",
    "        warnings.warn(f\"No matches in {target_name} - {sci_targname} - {instrument.lower()}\")\n",
    "        spec[\"data\"][\"spectral_element\"] = \"OUTER FAILURE\"\n",
    "        spec[\"data\"][\"aperture\"] = \"OUTER FAILURE\"\n",
    "\n",
    "    return spec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:50<00:00,  1.29it/s]                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No warnings were raised.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_data(fac: List[str], ins: List[str], split_transmission: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes data by filtering the split_transmission list based on the ins list and retrieving\n",
    "    MAST observation data for each filtered element.\n",
    "\n",
    "    Args:\n",
    "        ins (List[str]): A list of instrument names to filter the split_transmission list.\n",
    "        split_transmission (List[Dict]): A list of dictionaries containing transmission data for each instrument.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the concatenated MAST observation data for the filtered instruments.\n",
    "    \"\"\"\n",
    "    new_split_transmission = []\n",
    "\n",
    "    # Iterate through the filtered list of split_transmission elements based on the ins list\n",
    "    spec_iterable = tqdm([spec for spec in split_transmission if (spec[\"instrument\"] in ins and spec[\"facility\"] in fac)])\n",
    "    for spec in spec_iterable:\n",
    "        spec_iterable.set_postfix_str(\"\")\n",
    "        # Append the MAST observation data for the current instrument specification\n",
    "        new_split_transmission.append(get_mast_obs_data(spec, pbar=spec_iterable))\n",
    "\n",
    "    # Concatenate the MAST observation data for all filtered instruments\n",
    "    df_out_with_spectral_elements = pd.concat([spec[\"data\"] for spec in new_split_transmission], axis=0)\n",
    "\n",
    "    return df_out_with_spectral_elements\n",
    " \n",
    "ins = [\"Wide Field Camera 3\", \"Space Telescope Imaging Spectrograph\", \"WFC3\", \"WFC\", \"STIS\"]\n",
    "fac = [\"HST\", \"Hubble Space Telescope\", \"Hubble Space Telescope satellite\"]\n",
    "\n",
    "output_df = run_function_with_warnings_filtered(process_data, fac, ins, split_transmission)\n",
    "output_df.to_csv(WDIR / \"data/transitspec_with_spectral_elements.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
